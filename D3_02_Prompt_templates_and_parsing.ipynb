{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e525c82",
   "metadata": {},
   "source": [
    "## Prompt Templates, Few-Shot Learning & Output Parsing\n",
    "\n",
    "This notebook demonstrates how to use LangChain's Prompt Templates, few-shot prompting techniques, and structured output parsing with a local open-source language model.\n",
    "\n",
    "We will use the instruction-tuned model `\"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\"` throughout, and explore:\n",
    "- Prompt templates for reusability and clarity\n",
    "- Few-shot prompting to guide the model with examples\n",
    "- Structured output parsing using Pydantic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2898a88",
   "metadata": {},
   "source": [
    "### Prompt Templates in LangChain\n",
    "\n",
    "LangChainâ€™s `PromptTemplate` lets you define reusable prompt structures with placeholders for dynamic input.\n",
    "\n",
    "```python\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Explain the following topic in simple terms:\n",
    "\n",
    "{topic}\"\n",
    ")\n",
    "\n",
    "print(prompt.format(topic=\"What is machine learning?\"))\n",
    "```\n",
    "\n",
    "This is helpful for keeping prompts clean and consistent across inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c536fc1d-12aa-4840-a76a-3c3b3c1985aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "from langchain_huggingface import ChatHuggingFace\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, AIMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "import json\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f9421c4-ffbc-48dc-9a3a-743d4d5bccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_model = \"/gpfs/data/fs70824/LLMs_models_datasets/models\" # on VSC5\n",
    "path_to_model = \"/leonardo_scratch/fast/EUHPC_D20_063/huggingface/models/Nous-Hermes-2-Mistral-7B-DPO\" # on Leonardo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "897f3e73-dbf1-4432-bc20-cbe0747e81fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c9e98a36a3450c99daf5da1bd5335c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# model_id = \"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\" # on VSC5\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(path_to_model)\n",
    "model = AutoModelForCausalLM.from_pretrained(path_to_model, local_files_only=True, device_map=\"auto\")\n",
    "\n",
    "text_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=text_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d14290b0-57bd-4e1c-8574-88ac922aa886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain the following topic in simple terms:\n",
      "\n",
      "What is machine learning?\n"
     ]
    }
   ],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Explain the following topic in simple terms:\\n\\n{topic}\"\n",
    ")\n",
    "\n",
    "print(prompt_template.format(topic=\"What is machine learning?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f4e2ec8-cd92-48fe-98b2-a5f09b1476cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Machine learning is a subset of artificial intelligence. It involves training a computer or software program to identify patterns in data, and then apply these patterns to new data, making predictions or decisions on this new data. Essentially, machine learning allows a computer to learn from data, without being explicitly programmed.\n",
      "\n",
      "For example, machine learning can be used to create a system that can identify fraudulent credit card transactions. By training the system on a set of historical data that includes both fraudulent and non-fraudulent transactions, the system can learn to recognize the patterns that are typical of fraudulent transactions. Once the system has learned these patterns, it can then apply them to new data, quickly flagging any new transactions that match these patterns as potentially fraudulent, enabling the credit card company to take appropriate action.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(prompt_template.format(topic=\"What is machine learning?\"))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a88950-cbb6-45bd-b61f-1486d56ecddf",
   "metadata": {},
   "source": [
    "<br>\n",
    "Let's have a look at another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5803b574-debc-4b74-b33b-496680a81d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "simplify_prompt = PromptTemplate(\n",
    "    input_variables=[\"clause\"],\n",
    "    template=\"\"\"\n",
    "You are a legal assistant that simplifies complex legal clauses into plain, understandable English.\n",
    "\n",
    "Clause:\n",
    "{clause}\n",
    "\n",
    "Simplified Explanation:\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd9ffdbc-cbd6-49c4-82cd-33fe8b266187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified:\n",
      " The person renting the property (lessee) promises to cover and protect the person or company owning the property (lessor) from any problems or costs that may come up due to someone using the property. However, this does not apply if the problem is caused by a serious lack of care or attention.\n"
     ]
    }
   ],
   "source": [
    "legal_clause = (\n",
    "    \"The lessee shall indemnify and hold harmless the lessor from any liabilities, damages, \"\n",
    "    \"or claims arising out of the use of the premises, except in cases of gross negligence.\"\n",
    ")\n",
    "\n",
    "formatted_prompt = simplify_prompt.format(clause=legal_clause)\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "print(\"Simplified:\\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac30a4f-a1bd-43d3-914a-5a131a927e95",
   "metadata": {},
   "source": [
    "Let's try the same thing with OpenAI's API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21496ae9-638e-422f-9819-d1c4058e59b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API key (input is hidden): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3962e891-f109-4579-b470-ca1fe4536c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Create an LLM that talks to OpenAI (reads OPENAI_API_KEY from env)\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7,     # like HF's temperature\n",
    "    max_tokens=512       # analogous to HF's max_new_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b80cddd-fca7-4236-9f17-61e59f3254a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "print(\"Simplified:\\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a117a35-c3a6-4bfd-b46e-fc144a4683ac",
   "metadata": {},
   "source": [
    "### Few Shot Prompt Template\n",
    "\n",
    "Let's go over an example where you want a historical conversation to show the LLM Chat Bot a few examples, known as \"Few Shot Prompts\". We essentially provide some examples *before* sending the message history to the LLM. Be careful not to make the entire message too long, as you may hit context limits (but the latest models have quite large contexsts.\n",
    "\n",
    "LangChain distinguishes between:\n",
    "\n",
    " - PromptTemplates for simple string prompts\n",
    " - MessagePromptTemplates for structured chat-style prompts using roles like system, user, assistant\n",
    "\n",
    "So SystemMessagePromptTemplate helps build structured prompts that work with ChatModels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5810213-483b-44fe-8d0a-55d20b7e06e9",
   "metadata": {},
   "source": [
    "**Creating Example Inputs and Outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be9ac832-93de-4653-9912-1cd585c86063",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a helpful assistant that translates complex legal terms into plain and understandable language.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3c0aace-77d1-4ca4-9f51-7c1145a37fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_text_1 = \"Notwithstanding any provision to the contrary herein, the indemnitor agrees to indemnify, defend, and hold harmless the indemnitee from and against any and all claims, liabilities, damages, or expenses (including, without limitation, reasonable attorneyâ€™s fees) arising out of or related to the indemnitorâ€™s acts or omissions, except to the extent that such claims, liabilities, damages, or expenses result from the gross negligence or willful misconduct of the indemnitee.\"\n",
    "example_input_1 = HumanMessagePromptTemplate.from_template(legal_text_1)\n",
    "\n",
    "plain_text_1 = \"One party agrees to cover any costs, claims, or damages that happen because of their actions, including legal fees. However, they do not have to pay if the other party was extremely careless or acted intentionally wrong.\"\n",
    "example_output_1 = AIMessagePromptTemplate.from_template(plain_text_1)\n",
    "\n",
    "legal_text_2 = \"This agreement shall be binding upon and inure to the benefit of the parties hereto and their respective heirs, executors, administrators, successors, and assigns, and shall not be assignable by either party without the prior written consent of the other, except that either party may assign its rights and obligations hereunder in connection with a merger, consolidation, or sale of substantially all of its assets.\"\n",
    "example_input_2 = HumanMessagePromptTemplate.from_template(legal_text_2)\n",
    "\n",
    "plain_text_2 = \"This agreement applies to both parties and their future representatives, such as heirs or business successors. Neither party can transfer their rights under this agreement to someone else unless they get written permission. However, if one party merges with another company or sells most of its assets, they can transfer their rights without permission.\"\n",
    "example_output_2 = AIMessagePromptTemplate.from_template(plain_text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c651577-c2d3-4a43-9edb-125119579da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = \"{legal_text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4842eb22-7da0-4293-93af-f41f60bde6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, example_input_1, example_output_1, example_input_2, example_output_2, human_message_prompt]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3430799-dd3f-4dad-a739-253778b5b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_example_text = \"Any waiver of any term or condition of this agreement shall not be deemed a continuing waiver of such term or condition, nor shall it be considered a waiver of any other term or condition hereof. No failure or delay by either party in exercising any right, power, or privilege under this agreement shall operate as a waiver thereof, nor shall any single or partial exercise preclude any other or further exercise thereof or the exercise of any other right, power, or privilege.\"\n",
    "request = chat_prompt.format_prompt(legal_text=some_example_text).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4521c9dd-cb8d-4257-9165-da15048534f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1368bca7-f36e-4e2d-b752-28db75b94b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI: If one side lets something go without enforcing it, that doesn't mean they give up the right to enforce it in the future. Also, one action does not prevent them from taking further action or enforcing other parts of the agreement.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41256428-52a2-4def-9282-2ebeffcdf2ad",
   "metadata": {},
   "source": [
    "### Parsing output\n",
    "\n",
    "Large language models (LLMs) typically generate free-form text, which is great for human conversation â€” but not ideal when we want to **extract specific information** or **automate downstream tasks**.\n",
    "\n",
    "---\n",
    "\n",
    "**The Problem**\n",
    "Imagine asking an LLM:\n",
    "\n",
    "> \"Summarize this contract and give me the parties involved, the start date, and any penalties.\"\n",
    "\n",
    "If the model responds with a long paragraph, it becomes difficult to:\n",
    "- Reliably extract the pieces you need\n",
    "- Validate whether the answer is complete\n",
    "- Feed the output into another system\n",
    "\n",
    "---\n",
    "\n",
    "**The Solution**\n",
    "Structured Output (e.g. JSON)\n",
    "By instructing the LLM to return data in a structured format like JSON, we can:\n",
    "- Parse the output automatically, although this does not always work\n",
    "- Validate that required fields are present\n",
    "- Integrate with other tools and code seamlessly\n",
    "\n",
    "---\n",
    "\n",
    "Structured output turns the LLM into a more reliable component of your application.  \n",
    "Parsing with tools like Pydantic ensures your data is clean, complete, and ready for automation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4d10e4-903a-4725-a968-c4c6b91e1a92",
   "metadata": {},
   "source": [
    "**Define format**\n",
    "Let's first see if we can get the output in form of a JSON object, by adding that request to the system prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61b0df47-38b6-405b-aa43-428dfd4f83e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a helpful assistant that translates complex legal terms into plain and understandable language.  Respond only with a JSON object containing a single key 'translation' and its corresponding value.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cde1bbce-46b8-4b9a-84be-06691593e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, example_input_1, example_output_1, example_input_2, example_output_2, human_message_prompt]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0481b8f3-7fdc-489e-abda-50c594cde391",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_example_text = \"Any waiver of any term or condition of this agreement shall not be deemed a continuing waiver of such term or condition, nor shall it be considered a waiver of any other term or condition hereof. No failure or delay by either party in exercising any right, power, or privilege under this agreement shall operate as a waiver thereof, nor shall any single or partial exercise preclude any other or further exercise thereof or the exercise of any other right, power, or privilege.\"\n",
    "request = chat_prompt.format_prompt(legal_text=some_example_text).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3da3153-3911-4c0e-9201-7f4b8503b98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c484399-9980-44a0-9fe4-229d7b71f6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAI: If any part of this agreement is ignored or forgiven, it doesn't mean other parts can be ignored too. Also, not using a right, power, or privilege at one time doesn't stop it from being used in the future, and using it once doesn't prevent using it again or using other rights, powers, or privileges.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151c68b1-4d80-44bc-b30c-1970bfd38b50",
   "metadata": {},
   "source": [
    "That clearly didn't do the trick.\n",
    "\n",
    "#### Pydantic\n",
    "\n",
    "[Pydantic](https://docs.pydantic.dev/) is a Python library for defining data models with validation. With LangChain, it allows you to:\n",
    "- Define the structure you expect from the model\n",
    "- Automatically parse the raw LLM output\n",
    "- Catch errors if fields are missing or malformed\n",
    "\n",
    "---\n",
    "\n",
    "**Example**\n",
    "\n",
    "1. Define a Pydantic model\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "class ClauseSummary(BaseModel):\n",
    "    parties: List[str]\n",
    "    start_date: str\n",
    "    penalty_clause: str\n",
    "```\n",
    "\n",
    "This defines the structure we want the LLM to return â€” a JSON object with:\n",
    "- A list of `parties`\n",
    "- A `start_date`\n",
    "- A `penalty_clause` string\n",
    "\n",
    "---\n",
    "\n",
    "2. Set up a parser using LangChain\n",
    "\n",
    "```python\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=ClauseSummary)\n",
    "```\n",
    "\n",
    "This parser will take a raw string (from the LLM) and try to convert it into a `ClauseSummary` object.\n",
    "\n",
    "---\n",
    "\n",
    "3. Include the schema in the system prompt\n",
    "\n",
    "```python\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"clause\", \"format_instructions\"],\n",
    "    template=\"\"\"\n",
    "Extract the following fields from the contract clause below and return them in **valid JSON format ONLY**, with no extra text or explanation.\n",
    "\n",
    "Clause:\n",
    "{clause}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    ")\n",
    "```\n",
    "\n",
    "> The `format_instructions` tells the LLM exactly what JSON structure to return, based on your Pydantic model.\n",
    "\n",
    "---\n",
    "\n",
    "4. Run the LLM and parse the output\n",
    "\n",
    "```python\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "try:\n",
    "    parsed = parser.parse(response.content)\n",
    "    print(parsed.dict())\n",
    "except Exception as e:\n",
    "    print(\"Could not parse output.\")\n",
    "    print(\"Raw response:\", response.content)\n",
    "    print(e)\n",
    "```\n",
    "\n",
    "If the model returns a correctly structured JSON string, you now get a real Python object with attributes you can use:\n",
    "```python\n",
    "parsed.parties\n",
    "parsed.start_date\n",
    "parsed.penalty_clause\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "With this model, you can ensure the LLM responds in a way that fits your expected format â€” or fail gracefully when it doesn't.<br>\n",
    "Let's try out this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1236a684-3400-4633-8113-adb00f23bba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output structure\n",
    "class ClauseSummary(BaseModel):\n",
    "    parties: List[str]\n",
    "    start_date: str\n",
    "    penalty_clause: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54ab9521-9fa6-4867-9827-7dc530172660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parser\n",
    "parser = PydanticOutputParser(pydantic_object=ClauseSummary)\n",
    "format_instructions = parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49bb724a-2656-4e01-b5aa-3416c9ecaae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prompt with correct input variables\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"clause\", \"format_instructions\"],\n",
    "    template=\"\"\"\n",
    "Extract the following fields from the contract clause below and return them in **valid JSON format ONLY**, with no extra text or explanation.\n",
    "\n",
    "Clause:\n",
    "{clause}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebf4027a-ddc3-45d7-b3b4-f20f78813133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clause to parse\n",
    "clause_text = (\n",
    "    \"The agreement between Acme Corp and Beta LLC begins on January 1, 2025. \"\n",
    "    \"If either party breaks the agreement, a â‚¬5,000 penalty applies.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e09afd49-512e-450e-8802-567171dd4ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the full prompt\n",
    "full_prompt = prompt.format(clause=clause_text, format_instructions=format_instructions)\n",
    "\n",
    "# Run the model\n",
    "response = llm.invoke(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8db3a38-a04b-4ed6-aa4b-4cff153e670d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parties': ['Acme Corp', 'Beta LLC'], 'start_date': 'January 1, 2025', 'penalty_clause': 'â‚¬5,000 penalty'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_984514/1447590507.py:4: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  print(parsed.dict())\n"
     ]
    }
   ],
   "source": [
    "# Parse the response\n",
    "try:\n",
    "    parsed = parser.parse(response)\n",
    "    print(parsed.dict())\n",
    "except Exception as e:\n",
    "    print(\"Could not parse output.\")\n",
    "    print(\"Raw response:\", response)\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36fb97fa-5db3-43fe-97ec-f8fa1efa70da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Acme Corp', 'Beta LLC']\n",
      "January 1, 2025\n",
      "â‚¬5,000 penalty\n"
     ]
    }
   ],
   "source": [
    "print(parsed.parties)\n",
    "print(parsed.start_date)\n",
    "print(parsed.penalty_clause)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a9bc0f-527c-47c1-a958-31d0544e1343",
   "metadata": {},
   "source": [
    "<br>\n",
    "Let's try that on the example which tried to simplify legal clauses and output them in the JASON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35952ebc-c6dc-4616-86af-649a2360baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output schema with Pydantic \n",
    "class LegalSimplification(BaseModel):\n",
    "    translation: str\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=LegalSimplification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b075cd6-5d7b-4369-88bf-cef23a78deb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system prompt\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "system_message = SystemMessage(content=(f\"\"\"\n",
    "    \"You are a helpful assistant that translates complex legal terms into plain and understandable language. \"\n",
    "    \"Respond only with in this format {format_instructions}\"\n",
    "    \"Do not ask for clarification. Always use the given legal input.\"\n",
    "    \"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3072eaa7-fd00-4284-b737-ef6f1a16df63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define few-shot examples\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Notwithstanding any provision to the contrary herein, the indemnitor agrees to indemnify, defend, and hold harmless the indemnitee...\",\n",
    "        \"output\": \"One party agrees to cover any costs, claims, or damages that happen because of their actions...\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"This agreement shall be binding upon and inure to the benefit of the parties...\",\n",
    "        \"output\": \"This agreement applies to both parties and their future representatives...\"\n",
    "    }\n",
    "]\n",
    "\n",
    "few_shot_messages = []\n",
    "for ex in examples:\n",
    "    few_shot_messages.append(HumanMessage(content=ex[\"input\"]))\n",
    "    few_shot_messages.append(AIMessage(content=f'{{\"translation\": \"{ex[\"output\"]}\"}}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c78e204f-1955-4655-af6f-7504f1370ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the legal input text\n",
    "legal_text = (\n",
    "    \"Any waiver of any term or condition of this agreement shall not be deemed a continuing waiver of such term \"\n",
    "    \"or condition, nor shall it be considered a waiver of any other term or condition hereof. No failure or delay \"\n",
    "    \"by either party in exercising any right, power, or privilege under this agreement shall operate as a waiver \"\n",
    "    \"thereof, nor shall any single or partial exercise preclude any other or further exercise thereof or the \"\n",
    "    \"exercise of any other right, power, or privilege.\"\n",
    ")\n",
    "\n",
    "user_message = HumanMessage(content=legal_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ba67b1b-35c1-423d-be14-16a553fea991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===== Prompt Sent to Model =====\n",
      "SYSTEM: \n",
      "    \"You are a helpful assistant that translates complex legal terms into plain and understandable language. \"\n",
      "    \"Respond only with in this format The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"translation\": {\"title\": \"Translation\", \"type\": \"string\"}}, \"required\": [\"translation\"]}\n",
      "```\"\n",
      "    \"Do not ask for clarification. Always use the given legal input.\"\n",
      "    \n",
      "\n",
      "HUMAN: Notwithstanding any provision to the contrary herein, the indemnitor agrees to indemnify, defend, and hold harmless the indemnitee...\n",
      "\n",
      "AI: {\"translation\": \"One party agrees to cover any costs, claims, or damages that happen because of their actions...\"}\n",
      "\n",
      "HUMAN: This agreement shall be binding upon and inure to the benefit of the parties...\n",
      "\n",
      "AI: {\"translation\": \"This agreement applies to both parties and their future representatives...\"}\n",
      "\n",
      "HUMAN: Any waiver of any term or condition of this agreement shall not be deemed a continuing waiver of such term or condition, nor shall it be considered a waiver of any other term or condition hereof. No failure or delay by either party in exercising any right, power, or privilege under this agreement shall operate as a waiver thereof, nor shall any single or partial exercise preclude any other or further exercise thereof or the exercise of any other right, power, or privilege.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build full message list\n",
    "messages = [system_message] + few_shot_messages + [user_message]\n",
    "\n",
    "# Sanity check the prompt\n",
    "print(\"\\n\\n===== Prompt Sent to Model =====\")\n",
    "for m in messages:\n",
    "    print(f\"{m.type.upper()}: {m.content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "efc091d7-a383-47e3-aadb-13330bf88d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Create HF text-generation pipeline (in this case with sampling for creativity)\n",
    "hf_pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    return_full_text=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75736be7-dc37-4c3c-9360-d97fce3912b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap in LangChain-compatible LLM\n",
    "wrapped_llm = HuggingFacePipeline(pipeline=hf_pipe)\n",
    "llm = ChatHuggingFace(llm=wrapped_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52cff459-192f-4dda-b7ad-e7b2eb335131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate model output\n",
    "raw_output = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ccb194c7-39ff-4f85-9526-cc59a276adcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"translation\": \"If one side gives up a part of this agreement, it doesn't mean they give up the whole thing or any other part. If one side doesn't use their rights, it doesn't mean they can't use them later or use other rights.\"}\n"
     ]
    }
   ],
   "source": [
    "print(raw_output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30226364-933a-445e-943a-2a3b153b6958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simplified translation:\n",
      "If one side gives up a part of this agreement, it doesn't mean they give up the whole thing or any other part. If one side doesn't use their rights, it doesn't mean they can't use them later or use other rights.\n",
      "\n",
      "Appended to simplified_output.json\n"
     ]
    }
   ],
   "source": [
    "# Extract valid JSON from output\n",
    "\n",
    "def extract_first_json(text):\n",
    "    match = re.search(r'\\{.*?\\}', text, re.DOTALL)\n",
    "    return match.group(0) if match else text.strip()\n",
    "\n",
    "try:\n",
    "    output_text = raw_output.content if isinstance(raw_output, AIMessage) else raw_output\n",
    "    clean_output = extract_first_json(output_text)\n",
    "    result = parser.parse(clean_output)\n",
    "\n",
    "    print(\"\\nSimplified translation:\")\n",
    "    print(result.translation)\n",
    "\n",
    "    # Combine original and simplified\n",
    "    entry = {\n",
    "        \"legal_text\": legal_text,\n",
    "        \"translation\": result.translation\n",
    "    }\n",
    "\n",
    "    # Load existing data if file exists\n",
    "    data = []\n",
    "    output_file = \"simplified_output.json\"\n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, \"r\") as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                if not isinstance(data, list):\n",
    "                    print(\"Warning: existing file is not a list. Overwriting.\")\n",
    "                    data = []\n",
    "            except json.JSONDecodeError:\n",
    "                data = []\n",
    "\n",
    "    # Append new entry\n",
    "    data.append(entry)\n",
    "\n",
    "    # Write back to file\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "    print(f\"\\nAppended to {output_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"\\nCould not parse output.\")\n",
    "    print(\"Raw output:\", raw_output)\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3814bbb-8f47-434d-acd1-b1cd3d0064b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "title": "Few-Shot Prompting and Output Parsing with Prompt Templates"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
