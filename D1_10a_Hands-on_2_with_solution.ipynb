{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13af6941-248a-4521-8564-c6958c214fee",
   "metadata": {},
   "source": [
    "## Recap and Skill Test\n",
    "\n",
    "In this notebook, you will recap the skills you've learned about **Quantization, Parameter-Efficient Fine-Tuning (PEFT), and Unsloth** techniques. You will apply these methods to memory-efficiently finetune a lange model.\n",
    "\n",
    "### Objectives:\n",
    "\n",
    "1. **Quantize a Model**: Apply 4-bit quantization when loading a pre-trained model.\n",
    "2. **Parameter-Efficient Fine-Tuning (PEFT)**: Use adapter layers to fine-tune a model efficiently.\n",
    "\n",
    "## Task:\n",
    "\n",
    "1. Choose a different pre-trained model from the Huggingface Hub (e.g., Mistral 7B Instruct).\n",
    "2. Load the model using 4-bit quantization.\n",
    "3. Finetune the model on a dataset of your choice (e.g., vicgalle/alpaca-gpt4).\n",
    "4. Evaluate the model's performance before and after finetuning.\n",
    "\n",
    "### Hints:\n",
    "\n",
    "Some models' tokenizers do not come with a `pad_token`. It might be necessary to manually set the `pad_token` to some other token, e.g.:\n",
    "```\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "```\n",
    "\n",
    "In my example, I am going to use `mistralai/Mistral-7B-Instruct-v0.3`, which is a gated model. You need a Huggingface account and ask for access to the model. Then you need to get an account token from https://huggingface.co/settings/tokens and execute `huggingface-cli login` in a Terminal tab in JupyterHub.\n",
    "\n",
    "If you want to use Mistral 7B Instruct, you can also use the following path so that we do not download the same model 50 times:\n",
    "```\n",
    "'/leonardo_scratch/fast/EUHPC_D20_063/huggingface/models/mistralai--Mistral-7B-Instruct-v0.3'\n",
    "```\n",
    "Even if you use the model from the filesystem, I would suggest that you still go to the Huggingface Hub and have a look at the list of models and datasets there. You may also create an account, if you don't have one yet, and run `huggingface-cli login`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a29e6d9-68a4-4be6-96b2-5e1ba2b518ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/conda_container_env/lib/python3.11/site-packages/plink/gui.py:33: UserWarning: Plink failed to import tkinter, GUI will not be available\n",
      "  warnings.warn('Plink failed to import tkinter, GUI will not be available')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from accelerate import PartialState\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from trl import SFTTrainer, SFTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61a95d91-a552-42cc-a943-87e078b80778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb119feb8d4642708d6b13f12e50a9ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_id = 'mistralai/Mistral-7B-Instruct-v0.3'\n",
    "model_id = '/leonardo_scratch/fast/EUHPC_D20_063/huggingface/models/mistralai--Mistral-7B-Instruct-v0.3'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "tokenizer.padding_side = 'right'\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quantization_config,\n",
    "    attn_implementation='sdpa',  # 'eager', 'sdpa', or \"flash_attention_2\"\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed2a8ceb-e0f7-4f74-bb39-fe8f696a795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset('vicgalle/alpaca-gpt4', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f9cf701-2f9d-4fe5-a8b8-f3b46cdf238e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'text'],\n",
       "    num_rows: 52002\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa700be0-f4f2-4c2e-8900-5e3edc828418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Give three tips for staying healthy.',\n",
       " 'input': '',\n",
       " 'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.',\n",
       " 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGive three tips for staying healthy.\\n\\n### Response:\\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62961264-950f-49be-ba67-45b161bdadc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda entry: {'text_mistral7b': tokenizer.apply_chat_template([\n",
    "    {'role': 'user', 'content': entry['instruction']},\n",
    "    {'role': 'assistant', 'content': entry['output']}\n",
    "], tokenize=False)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a91feef1-104e-4dee-a818-50ed7b3058da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Give three tips for staying healthy.',\n",
       " 'input': '',\n",
       " 'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.',\n",
       " 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGive three tips for staying healthy.\\n\\n### Response:\\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.',\n",
       " 'text_mistral7b': '<s>[INST] Give three tips for staying healthy.[/INST] 1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.</s>'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ec73eab-cd44-463c-9e65-49807b1cc08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type='CAUSAL_LM',\n",
    "    r=16,\n",
    "    lora_alpha=32,  # rule: lora_alpha should be 2*r\n",
    "    lora_dropout=0.05,\n",
    "    bias='none',\n",
    "    target_modules='all-linear',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eabf9e97-6f84-4177-bb9e-2ef48a1877a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = SFTConfig(\n",
    "    output_dir='output/mistral7b-alpaca-gpt4',\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=1,\n",
    "    gradient_checkpointing=True, # Gradient checkpointing improves memory efficiency, but slows down training,\n",
    "        # e.g. Mistral 7B with PEFT using bitsandbytes:\n",
    "        # - enabled: 11 GB GPU RAM and 8 samples/second\n",
    "        # - disabled: 40 GB GPU RAM and 12 samples/second\n",
    "    gradient_checkpointing_kwargs={'use_reentrant': False},  # Use newer implementation that will become the default.\n",
    "    optim='adamw_torch',  # 'paged_adamw_32bit' can save GPU memory\n",
    "    learning_rate=2e-4,  # QLoRA suggestions: 2e-4 for 7B or 13B, 1e-4 for 33B or 65B\n",
    "    warmup_steps=200,\n",
    "    lr_scheduler_type='cosine',\n",
    "    logging_strategy='steps',  # 'no', 'epoch' or 'steps'\n",
    "    logging_steps=10,\n",
    "    save_strategy='no',  # 'no', 'epoch' or 'steps'\n",
    "    max_steps=100,\n",
    "    bf16=True,  # mixed precision training\n",
    "    report_to='none',  # disable wandb\n",
    "    dataset_text_field='text_mistral7b',\n",
    "    max_seq_length=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be382fd8-5550-4203-a7b9-305f4f5efbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-21 20:12:20,931] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=data,\n",
    "    peft_config=peft_config,  # We can let the Trainer do the `model = get_peft_model(model, peft_config)`.\n",
    "    processing_class=tokenizer,\n",
    "    # formatting_func=formatting_func,\n",
    "    # This time, we do not specify a formatting_func, but let it take a specific column of the dataset,\n",
    "    # which is specified using the parameter `dataset_text_field` in SFTConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3097c846-861a-4f52-806d-62dc1d91c398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 41,943,040 || all params: 7,289,966,592 || trainable%: 0.5754\n"
     ]
    }
   ],
   "source": [
    "if hasattr(trainer.model, \"print_trainable_parameters\"):\n",
    "    trainer.model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3388e1ba-f6fc-41ee-b808-019ae3bd5dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 02:47, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.823100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.606800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.451500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.407600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.131700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.238900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.199800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.128700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.134500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.202400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 170.14 seconds\n",
      "Training speed: 4.7 samples/s\n"
     ]
    }
   ],
   "source": [
    "result = trainer.train()\n",
    "\n",
    "# Print statistics:\n",
    "print(f\"Run time: {result.metrics['train_runtime']:.2f} seconds\")\n",
    "print(f\"Training speed: {result.metrics['train_samples_per_second']:.1f} samples/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c90dee5c-0285-4339-8472-6e86a1b377c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f6bf37-c41f-4653-b97c-98ed4ee2aa26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
